{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"EleutherAI/pythia-2.8B-deduped\",\n",
    "  revision=\"step143000\",\n",
    "  cache_dir=\"./pythia-2.8B-deduped/step143000\",\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-2.8B-deduped\",\n",
    "  revision=\"step143000\",\n",
    "  cache_dir=\"./pythia-2.8B-deduped/step143000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num_added_toks = tokenizer.add_tokens([\"[\",\"]\",\"->\"], special_tokens=True)\n",
    "print(num_added_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50281, 2560)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_tokens) \n",
    "# doesn't show our new ones for some reason /shrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  262,   310,   209,    60, 22731,  1082,   209,  1168, 15567,    62],\n",
      "       device='cuda:0')\n",
      "['it', 'Ġis', 'Ġ', '[', 'NOW', '()', 'Ġ', '->', 'Ġ123', ']']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(\"it is [NOW() -> 123]\", return_tensors=\"pt\").to(\"cuda\")[\"input_ids\"][0]\n",
    "print(tokens)\n",
    "print(tokenizer.convert_ids_to_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1904908, '', 'explorer.exe'),\n",
       " (65828, '', 'explorer.exe'),\n",
       " (65986, '', 'explorer.exe'),\n",
       " (66004, '', 'explorer.exe'),\n",
       " (132490, '● main.ipynb - toolformer - Visual Studio Code', 'Code.exe'),\n",
       " (187893914, 'pythia.ipynb - gptj - Visual Studio Code', 'Code.exe'),\n",
       " (265090, '', 'pwsh.exe'),\n",
       " (721110, 'PowerShell', 'WindowsTerminal.exe'),\n",
       " (460880,\n",
       "  'TeamDman/toolformer: Experimenting with toolformer prompting, simple notebooks inside and 4 more pages - Personal - Microsoft\\u200b Edge Dev',\n",
       "  'msedge.exe'),\n",
       " (9047612, '', 'ApplicationFrameHost.exe'),\n",
       " (2099944, '', 'svchost.exe'),\n",
       " (200150, '', 'explorer.exe'),\n",
       " (459980, 'Groove Music', 'Music.UI.exe'),\n",
       " (262342, 'Groove Music', 'ApplicationFrameHost.exe'),\n",
       " (197516, 'Settings', 'SystemSettings.exe'),\n",
       " (263536, 'Settings', 'ApplicationFrameHost.exe'),\n",
       " (66582, 'Microsoft Text Input Application', 'TextInputHost.exe'),\n",
       " (66108, '', 'explorer.exe'),\n",
       " (66126, '', 'explorer.exe'),\n",
       " (66144, '', 'explorer.exe'),\n",
       " (66152, '', 'explorer.exe'),\n",
       " (66078, '', 'explorer.exe'),\n",
       " (66076, '', 'explorer.exe'),\n",
       " (395350, '', 'explorer.exe'),\n",
       " (527764, '', 'explorer.exe'),\n",
       " (66034, 'Program Manager', 'explorer.exe')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_windows():\n",
    "    import psutil, win32process, win32gui, time\n",
    "    def get_process_name(handle):\n",
    "        pid = win32process.GetWindowThreadProcessId(handle) #This produces a list of PIDs active window relates to\n",
    "        return (psutil.Process(pid[-1]).name()) #pid[-1] is the most likely to survive last longer\n",
    "\n",
    "    rtn = []\n",
    "    def winEnumHandler( hwnd, ctx ):\n",
    "        nonlocal rtn\n",
    "        if win32gui.IsWindowVisible( hwnd ):\n",
    "            rtn.append((hwnd, win32gui.GetWindowText( hwnd ), get_process_name(hwnd)))\n",
    "    win32gui.EnumWindows( winEnumHandler, None )\n",
    "    return rtn\n",
    "list_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132490, '● main.ipynb - toolformer - Visual Studio Code', 'Code.exe')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132490"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_match(name):\n",
    "    from fuzzywuzzy import fuzz\n",
    "    x = sorted([(fuzz.ratio(str(x), name),x) for x in list_windows()], key=lambda x: x[0], reverse=True)\n",
    "    print(x[0][1])\n",
    "    return x[0][1][0]\n",
    "get_best_match(\"VSCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2048, 499, 1024, 576)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos2pos(pos: str) -> (int,int,int,int):\n",
    "    from screeninfo import get_monitors\n",
    "    monitors = get_monitors()\n",
    "    left = sorted(monitors, key=lambda x: x.x)[0]\n",
    "    right = sorted(monitors, key=lambda x: x.x, reverse=True)[0]\n",
    "    main = [x for x in monitors if x.is_primary][0]\n",
    "    corners = {\n",
    "        \"top left\": lambda m: (m.x, m.y, m.width//2, m.height//2),\n",
    "        \"top right\": lambda m: (m.x + m.width//2, m.y, m.width//2, m.height//2),\n",
    "        \"bottom left\": lambda m: (m.x, m.y + m.height//2, m.width//2, m.height//2),\n",
    "        \"bottom right\": lambda m: (m.x + m.width//2, m.y + m.height//2, m.width//2, m.height//2),\n",
    "    }\n",
    "    lookup = {}\n",
    "    for corner, func in corners.items():\n",
    "        lookup[f\"left monitor, {corner}\"] = func(left)\n",
    "        lookup[f\"third monitor, {corner}\"] = func(left)\n",
    "        lookup[f\"main monitor, {corner}\"] = func(main)\n",
    "        lookup[f\"second monitor, {corner}\"] = func(right)\n",
    "    lookup[f\"main monitor, full\"] = (main.x, main.y, main.width, main.height)\n",
    "    lookup[f\"left monitor, full\"] = (left.x, left.y, left.width, left.height)\n",
    "    lookup[f\"third monitor, full\"] = (left.x, left.y, left.width, left.height)\n",
    "    lookup[f\"right monitor, full\"] = (right.x, right.y, right.width, right.height)\n",
    "    lookup[f\"second monitor, full\"] = (right.x, right.y, right.width, right.height)\n",
    "\n",
    "    from fuzzywuzzy import fuzz\n",
    "    x = sorted([(fuzz.ratio(label, pos),data) for label,data in lookup.items()], key=lambda x: x[0], reverse=True)\n",
    "    # print(x)\n",
    "    return x[0][1]\n",
    "    \n",
    "pos2pos(\"right monitor, bottom left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap(params):\n",
    "    window, position = params.split(\",\")\n",
    "\n",
    "    import ctypes\n",
    "    user32 = ctypes.windll.user32\n",
    "\n",
    "    user32.SetProcessDPIAware()\n",
    "    res = (user32.GetSystemMetrics(0), user32.GetSystemMetrics(1))\n",
    "    print(\"found resolution: \", res)\n",
    "    handle = get_best_match(window)\n",
    "    # handle = user32.FindWindowW(None, u'Untitled - Notepad')\n",
    "    if handle == 0:\n",
    "        return \"could not find window\"\n",
    "    # move window using handle\n",
    "    # MoveWindow(handle, x, y, height, width, repaint(bool))\n",
    "    pos = pos2pos(position)\n",
    "    user32.MoveWindow(handle, *pos, True)\n",
    "    return f\"moved {window} to {position}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap(\"notepad, second monitor bottom left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_functions = {\n",
    "    \"SNAP\": lambda x: snap(x),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke(response):\n",
    "    import re\n",
    "    pattern = r\".*\\[(\\w+)\\((.*?)\\s*\\)\\s*->\"\n",
    "    print(re.findall(pattern, response, re.DOTALL))\n",
    "    x = re.findall(pattern, response)\n",
    "    if len(x) == 0:\n",
    "        return \"bad match\"\n",
    "    func, params = x[0]\n",
    "\n",
    "    if func not in known_functions:\n",
    "        return f\"Unknown function {func}\"\n",
    "    print(f\"Calling {func} with {params}\")\n",
    "    result = known_functions[func](params)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1168 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:187 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SNAP', 'notepad, main monitor top right')]\n",
      "Calling SNAP with notepad, main monitor top right\n",
      "found resolution:  (1920, 1080)\n",
      "(264808, 'Untitled - Notepad', 'notepad.exe')\n",
      "[(96, (960, 0, 960, 540)), (86, (960, 540, 960, 540)), (81, (-1024, -77, 1024, 576)), (80, (0, 0, 960, 540)), (79, (2880, 0, 960, 540)), (78, (-1024, -77, 1024, 576)), (72, (-1024, 499, 1024, 576)), (71, (0, 540, 960, 540)), (71, (2880, 540, 960, 540)), (69, (-1024, 499, 1024, 576)), (65, (-2048, -77, 1024, 576)), (64, (1920, 0, 960, 540)), (63, (0, 0, 1920, 1080)), (62, (-2048, -77, 1024, 576)), (57, (-2048, 499, 1024, 576)), (56, (1920, 540, 960, 540)), (54, (-2048, 499, 1024, 576)), (48, (-2048, -77, 2048, 1152)), (48, (1920, 0, 1920, 1080)), (47, (1920, 0, 1920, 1080)), (44, (-2048, -77, 2048, 1152))]\n",
      "You are an AI assistant with several tools available to you. The tools are the following:\n",
      "MATH: This allows you to evaluate mathematical expressions using the math.js library.\n",
      "NOW: This returns the current date and time. You must not pass any arguments to this tool!\n",
      "SEARCH: This returns a web search result for the given string argument.\n",
      "REMEMBER: This stores a key-value pair in the assistant's memory. You must pass two arguments to this tool, the first being the key, and the second being the value.\n",
      "RECALL: This returns a value from the assistant's memory. You must pass one argument to this tool, the key.\n",
      "OPEN: This opens a file or a website. The only argument is the URI for the file or website.\n",
      "SNAP: This moves a window to an area of the screen. The first argument is the program, and the second argument is the position.\n",
      "\n",
      "DO NOT USE TOOLS WITHIN TOOLS! KEEP ALL TOOL CALLS SEPARATE FROM EACH OTHER!\n",
      "\n",
      "User: What is 10 times 14?\n",
      "Assistant:10 * 14 is [MATH(10 * 14) -> 140] 140.\n",
      "User: Has Avatar the way of water been released yet?\n",
      "Assistant:[SEARCH(Avatar the way of water release date) -> 22.11.2022] Avatar: The way of water was released on the 22nd of november 2022. Today is [NOW() -> Mon Feb 27 2023] the 13th of February 2023. Therefore, [MATH(2023 > 2022) -> true] it was released last year.\n",
      "User: What day is it?\n",
      "Assistant:It is [NOW() -> 13/02/2023, 20:01:35] the 13th of February 2023.\n",
      "User: How old is Donald Trump?\n",
      "Assistant:Donald Trump is [SEARCH(Donald Trump age) -> 76] 76 years old.\n",
      "User: Where was the inventor of the light bulb born, and what is the last country his home country was at war with?\n",
      "Assistant:Thomas Edison, the inventor of the lightbulb, was born in [SEARCH(Thomas Edison birthplace) -> Milan, Ohio] Milan, Ohio. The last country the United States was at war with was [SEARCH(last country US at war with) -> Iraq] Iraq.\n",
      "User: Set my default browser to Firefox.\n",
      "Assistant:Okay, I set your default browser to [REMEMBER(default browser, Firefox) -> Firefox].\n",
      "User: Open youtube.\n",
      "Assistant: Okay, opening YouTube... [OPEN(https://youtube.com) -> 0] done!\n",
      "User: Open my csgo config.\n",
      "Assistant: Okay, opening your csgo config... [OPEN(C:\\Program Files (x86)\\Steam\\steamapps\\common\\Counter-Strike Global Offensive\\csgo\\cfg\\autoexec.cfg) -> 0] done!\n",
      "User: Move spotify to my left monitor.\n",
      "Assistant: Okay, moving spotify... [SNAP(Spotify, left monitor) -> 0] done!\n",
      "User: Move spotify to the top right corner of my second monitor.\n",
      "Assistant: Okay, moving spotify... [SNAP(Spotify, right monitor top right) -> 0] done!\n",
      "User: Move spotify to the main monitor, top right.\n",
      "Assistant: Okay, moving spotify... [SNAP(Spotify, main monitor top right) -> 0] done!\n",
      "User: Move spotify to my third monitor\n",
      "Assistant: Okay, moving spotify... [SNAP(Spotify, third monitor) -> 0] done!\n",
      "User: move notepad, second monitor, top right\n",
      "Assistant: Okay, moving spotify... [SNAP(notepad, second monitor top right) -> 0] done!\n",
      "User: \n",
      "move notepad, main monitor, top right\n",
      "Assistant: Okay, moving spotify... [SNAP(notepad, main monitor top right) ->moved notepad to  main monitor top right]\n",
      " done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_prompt = r\"\"\"You are an AI assistant with several tools available to you. The tools are the following:\n",
    "MATH: This allows you to evaluate mathematical expressions using the math.js library.\n",
    "NOW: This returns the current date and time. You must not pass any arguments to this tool!\n",
    "SEARCH: This returns a web search result for the given string argument.\n",
    "REMEMBER: This stores a key-value pair in the assistant's memory. You must pass two arguments to this tool, the first being the key, and the second being the value.\n",
    "RECALL: This returns a value from the assistant's memory. You must pass one argument to this tool, the key.\n",
    "OPEN: This opens a file or a website. The only argument is the URI for the file or website.\n",
    "SNAP: This moves a window to an area of the screen. The first argument is the program, and the second argument is the position.\n",
    "\n",
    "DO NOT USE TOOLS WITHIN TOOLS! KEEP ALL TOOL CALLS SEPARATE FROM EACH OTHER!\n",
    "\n",
    "User: What is 10 times 14?\n",
    "Assistant:10 * 14 is [MATH(10 * 14) -> 140] 140.\n",
    "User: Has Avatar the way of water been released yet?\n",
    "Assistant:[SEARCH(Avatar the way of water release date) -> 22.11.2022] Avatar: The way of water was released on the 22nd of november 2022. Today is [NOW() -> Mon Feb 27 2023] the 13th of February 2023. Therefore, [MATH(2023 > 2022) -> true] it was released last year.\n",
    "User: What day is it?\n",
    "Assistant:It is [NOW() -> 13/02/2023, 20:01:35] the 13th of February 2023.\n",
    "User: How old is Donald Trump?\n",
    "Assistant:Donald Trump is [SEARCH(Donald Trump age) -> 76] 76 years old.\n",
    "User: Where was the inventor of the light bulb born, and what is the last country his home country was at war with?\n",
    "Assistant:Thomas Edison, the inventor of the lightbulb, was born in [SEARCH(Thomas Edison birthplace) -> Milan, Ohio] Milan, Ohio. The last country the United States was at war with was [SEARCH(last country US at war with) -> Iraq] Iraq.\n",
    "User: Set my default browser to Firefox.\n",
    "Assistant:Okay, I set your default browser to [REMEMBER(default browser, Firefox) -> Firefox].\n",
    "User: Open youtube.\n",
    "Assistant: Okay, opening YouTube... [OPEN(https://youtube.com) -> 0] done!\n",
    "User: Open my csgo config.\n",
    "Assistant: Okay, opening your csgo config... [OPEN(C:\\Program Files (x86)\\Steam\\steamapps\\common\\Counter-Strike Global Offensive\\csgo\\cfg\\autoexec.cfg) -> 0] done!\n",
    "User: Move spotify to my left monitor.\n",
    "Assistant: Okay, moving spotify... [SNAP(Spotify, left monitor) -> 0] done!\n",
    "User: Move spotify to the top right corner of my second monitor.\n",
    "Assistant: Okay, moving spotify... [SNAP(Spotify, right monitor top right) -> 0] done!\n",
    "User: Move spotify to the main monitor, top right.\n",
    "Assistant: Okay, moving spotify... [SNAP(Spotify, main monitor top right) -> 0] done!\n",
    "User: Move spotify to my third monitor\n",
    "Assistant: Okay, moving spotify... [SNAP(Spotify, third monitor) -> 0] done!\n",
    "User: move notepad, second monitor, top right\n",
    "Assistant: Okay, moving spotify... [SNAP(notepad, second monitor top right) -> 0] done!\n",
    "User: \n",
    "\"\"\"\n",
    "\n",
    "prompt = pre_prompt + \"move notepad, main monitor\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "# print(prompt)\n",
    "tokens = model.generate(\n",
    "    **inputs,\n",
    "    # do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_new_tokens=500,\n",
    "    eos_token_id=tokenizer.encode(\"->\")[0],\n",
    ")\n",
    "response = tokenizer.decode(tokens[:,inputs[\"input_ids\"].shape[1]:][0])\n",
    "output = invoke(response)\n",
    "prompt = prompt + response + output + \"]\"\n",
    "print(prompt)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "# print(prompt)\n",
    "tokens = model.generate(\n",
    "    **inputs,\n",
    "    # do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_new_tokens=100,\n",
    "    eos_token_id=tokenizer.encode(\"\\n\")[0],\n",
    ")\n",
    "response = tokenizer.decode(tokens[:,inputs[\"input_ids\"].shape[1]:][0])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " corner.\n",
      "Assistant: Okay, moving notepad... \n",
      "[SNAP(Notepad, main monitor, top left corner) \n",
      "->\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a091c563561efc8bc921af2d05a3a1115537b9cd9158ae425ad172b67cf38642"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
